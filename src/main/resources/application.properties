# application.properties
spring.application.name=refrigerator

# Database Configuration (H2 example)
spring.datasource.url=jdbc:h2:mem:fooddb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE
spring.datasource.driverClassName=org.h2.Driver
spring.datasource.username=sa
spring.datasource.password=password
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.jpa.hibernate.ddl-auto=update
spring.h2.console.enabled=true
spring.h2.console.path=/h2-console

# Flyway (Optional: if used)
# spring.flyway.enabled=true

# --- Spring AI - Ollama Configuration ---

# Required: Base URL of your running Ollama instance
# Default is http://localhost:11434 if Ollama runs locally with default port
spring.ai.ollama.base-url=http://localhost:11434

# Required: The name of the model you have downloaded and want to use in Ollama
# Examples: llama3, mistral, gemma:2b, phi3 etc. (Check 'ollama list' in your terminal)
spring.ai.ollama.chat.options.model=mistral

# Optional: Generation parameters
spring.ai.ollama.chat.options.temperature=0.7
# spring.ai.ollama.chat.options.top-k=40
# spring.ai.ollama.chat.options.top-p=0.9
# spring.ai.ollama.chat.options.num-predict=128 # Max tokens for Ollama

# Your custom prompt (optional, defined here or in code)
app.ai.system-prompt=Você é um assistente de culinária para uma geladeira inteligente. Sua tarefa é gerar receitas baseadas nos ingredientes fornecidos.