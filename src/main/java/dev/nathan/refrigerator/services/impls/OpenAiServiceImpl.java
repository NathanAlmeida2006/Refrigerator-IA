package dev.nathan.refrigerator.services.impls;

import dev.nathan.refrigerator.services.OpenAiService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.ai.chat.client.ChatClient;
import org.springframework.ai.chat.messages.SystemMessage;
import org.springframework.ai.chat.messages.UserMessage;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Primary;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.stream.Collectors;

@Service
@Primary
public class OpenAiServiceImpl implements OpenAiService {

    private static final Logger log = LoggerFactory.getLogger(OpenAiServiceImpl.class);

    private final ChatClient chatClient;

    // Inject the system prompt message
    @Value("${app.ai.system-prompt:'Você é um assistente de culinária para uma geladeira inteligente. Sua tarefa é gerar receitas baseadas nos ingredientes fornecidos.'}")
    private String systemPrompt;

    // Inject the configured Ollama model name directly
    @Value("${spring.ai.ollama.chat.options.model}")
    private String ollamaModelName;

    public OpenAiServiceImpl(ChatClient.Builder chatClientBuilder) {
        this.chatClient = chatClientBuilder.build();
        // Log the configured model during initialization
        log.info("Ollama Service Initialized using Spring AI ChatClient. Configured Model: {}", ollamaModelName);
    }

    @Override
    public String generateRecipe(List<String> ingredients) {
        if (ingredients == null || ingredients.isEmpty()) {
            log.warn("generateRecipe called with no ingredients.");
            return "Nenhum ingrediente fornecido para gerar uma receita.";
        }

        Prompt prompt = buildRecipePrompt(ingredients);
        // Use the injected model name field for logging
        log.info("Sending recipe generation request to Ollama (Model: {}) for ingredients: {}",
                ollamaModelName, // Use the injected field
                ingredients.stream().distinct().collect(Collectors.joining(", ")));

        try {
            String recipe = chatClient.prompt(prompt).call().content();

            if (recipe == null || recipe.isBlank()) {
                log.warn("Ollama service returned null or empty content for the ingredients provided.");
                return "A IA (Ollama) não conseguiu gerar uma receita com os ingredientes fornecidos.";
            }

            log.info("Recipe successfully generated by Ollama.");
            return recipe.trim();

        } catch (RuntimeException runtimeEx) {
            log.error("Runtime error during Ollama recipe generation [{}]: {}",
                    runtimeEx.getClass().getSimpleName(), runtimeEx.getMessage(), runtimeEx);
            throw runtimeEx;
        }
    }

    private Prompt buildRecipePrompt(List<String> ingredients) {
        String ingredientList = ingredients.stream().distinct().collect(Collectors.joining(", "));
        String userPromptContent = """
                Crie uma receita simples usando APENAS os seguintes ingredientes disponíveis: %s.
                Se não for possível criar uma receita razoável com esses itens, informe que não é possível.
                A receita deve incluir:
                1. Um título criativo.
                2. A lista de ingredientes (apenas os da lista fornecida que foram usados).
                3. Instruções de preparo passo a passo claras e concisas.
                """.formatted(ingredientList);

        SystemMessage systemMessage = new SystemMessage(systemPrompt);
        UserMessage userMessage = new UserMessage(userPromptContent);

        return new Prompt(List.of(systemMessage, userMessage));
    }
}